# ==========================================================
# utils.py ‚Äî Fun√ß√µes utilit√°rias do QA Or√°culo (vers√£o final)
# ==========================================================
# Este m√≥dulo re√∫ne todas as fun√ß√µes de suporte do projeto:
#   - Normaliza√ß√£o de strings e nomes de arquivos
#   - Exporta√ß√£o para Excel (XLSX) e CSV (Azure, Zephyr)
#   - Limpeza de relat√≥rios e parsing seguro de JSON
#   - Gera√ß√£o de CSV para Azure Test Plans com autodetec√ß√£o
#
# Tudo foi projetado para ser compreens√≠vel e √∫til ao QA:
#   üîπ C√≥digo limpo e documentado
#   üîπ Coment√°rios explicando a l√≥gica de cada regra
#   üîπ Compatibilidade garantida com Excel PT-BR e EN-US
# ==========================================================

import csv
import datetime
import io
import json
import locale
import re
import unicodedata

import pandas as pd

# ==========================================================
# NORMALIZA√á√ÉO E NOMES DE ARQUIVOS
# ==========================================================


def normalizar_string(texto: str) -> str:
    """Remove acentos e caracteres especiais de uma string."""
    nfkd_form = unicodedata.normalize("NFD", texto)
    return "".join([c for c in nfkd_form if not unicodedata.combining(c)])


def gerar_nome_arquivo_seguro(user_story: str, extension: str) -> str:
    """
    Gera nome de arquivo limpo, seguro e √∫nico, baseado na User Story.
    Inclui timestamp para evitar sobrescrita.
    """
    if not user_story:
        return f"relatorio_qa_oraculo.{extension}"

    primeira_linha_us = user_story.split("\n")[0].lower()
    nome_sem_acentos = normalizar_string(primeira_linha_us)
    nome_base = re.sub(r"[^\w\s-]", "", nome_sem_acentos).strip()
    nome_base = re.sub(r"[-_\s]+", "-", nome_base)[:50]
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"{nome_base}_{timestamp}.{extension}"


# ==========================================================
#  EXPORTA√á√ÉO PARA EXCEL
# ==========================================================


def to_excel(df: pd.DataFrame, sheet_name: str) -> bytes:
    """Converte um DataFrame Pandas em bytes de arquivo Excel."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl", mode="w") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    return output.getvalue()


# ==========================================================
#  EXPORTA√á√ÉO PARA JIRA ZEPHYR
# ==========================================================


def preparar_df_para_zephyr_xlsx(
    df_original: pd.DataFrame, priority: str, labels: str, description: str
) -> pd.DataFrame:
    """
    Converte cen√°rios de teste em DataFrame no formato aceito pelo Zephyr (Jira).
    Cada linha do DataFrame representa um passo do caso de teste.
    """
    zephyr_rows = []
    header = [
        "Issue Type",
        "Summary",
        "Priority",
        "Labels",
        "Description",
        "Test Step",
        "Expected Result",
    ]

    for index, row in df_original.iterrows():
        summary = row.get("titulo", f"Caso de Teste {index+1}")
        cenario_steps = row.get("cenario", [])

        if isinstance(cenario_steps, str):
            cenario_steps = [s.strip() for s in cenario_steps.split("\n") if s.strip()]
        if not cenario_steps:
            continue

        for i, step in enumerate(cenario_steps):
            zephyr_rows.append(
                {
                    "Issue Type": "Test",
                    "Summary": summary,
                    "Priority": priority,
                    "Labels": labels,
                    "Description": description if i == 0 else "",
                    "Test Step": step,
                    "Expected Result": "",
                }
            )

    return pd.DataFrame(zephyr_rows, columns=header)


# ==========================================================
#  FUN√á√ïES DE SUPORTE E LIMPEZA
# ==========================================================


def get_flexible(data_dict: dict, keys: list, default_value):
    """Busca flex√≠vel de valores por m√∫ltiplas chaves poss√≠veis."""
    if not isinstance(data_dict, dict):
        return default_value
    for key in keys:
        if key in data_dict:
            return data_dict[key]
    return default_value


def clean_markdown_report(report_text: str) -> str:
    """Remove blocos de c√≥digo Markdown do texto."""
    if not isinstance(report_text, str):
        return ""
    text = re.sub(r"^```[a-zA-Z]*\n", "", report_text.strip())
    text = re.sub(r"\n```$", "", text)
    return text.strip()


def parse_json_strict(s: str):
    """Faz parsing seguro de JSON retornado pela IA."""
    s = s.strip()
    if s.startswith("```"):
        s = s.lstrip("`")
        s = s[s.find("{") :]
    if s.endswith("```"):
        s = s.rstrip("`")
        s = s[: s.rfind("}") + 1]

    try:
        return json.loads(s)
    except json.JSONDecodeError as e:
        raise ValueError(f"Falha ao decodificar JSON: {e}") from e


# ==========================================================
#  EXPORTA√á√ÉO PARA AZURE TEST PLANS (CSV)
# ==========================================================


def gerar_csv_azure_from_df(  # noqa: C901
    df_original: pd.DataFrame,
    area_path: str,
    assigned_to: str,
    default_priority: str = "2",
    default_state: str = "Design",
) -> bytes:
    """
    Gera um CSV 100% compat√≠vel com Azure Test Plans.

    - A 1¬™ coluna "ID" √© obrigat√≥ria (vazia) ‚Äî Azure gera automaticamente.
    - Cada linha do DataFrame √© um Test Case.
    - Step 1 √© sempre o cabe√ßalho (sem a√ß√£o).
    - 'Dado', 'Quando', 'Ent√£o', 'E' s√£o mapeados conforme o formato Gherkin.
    - O delimitador √© detectado automaticamente com base no idioma do sistema:
        PT-BR ‚Üí usa ';'
        EN-US ‚Üí usa ','
    - Codifica√ß√£o UTF-8 com BOM ‚Üí compat√≠vel com Excel e Azure.
    """

    # üìå Autodetec√ß√£o de localidade do sistema (para decidir delimitador)
    loc = locale.getlocale()[0] or ""
    sep = ";" if "pt" in loc.lower() else ","

    header = [
        "ID",  # Coluna obrigat√≥ria, mesmo vazia
        "Work Item Type",
        "Title",
        "Test Step",
        "Step Action",
        "Step Expected",
        "Priority",
        "Area Path",
        "Assigned To",
        "State",
    ]

    buffer = io.StringIO()
    writer = csv.writer(buffer, delimiter=sep, quoting=csv.QUOTE_MINIMAL)
    writer.writerow(header)

    if df_original.empty:
        return buffer.getvalue().encode("utf-8-sig")

    area_path = (area_path or "").strip()
    assigned_to = (assigned_to or "").strip()

    # Mapeia texto de prioridade ‚Üí valor num√©rico
    priority_map = {
        "alta": "1",
        "high": "1",
        "m√©dia": "2",
        "media": "2",
        "medium": "2",
        "baixa": "3",
        "low": "3",
    }

    # Cada linha do DF √© um caso de teste
    for index, row in df_original.iterrows():
        title = row.get("titulo", f"Caso de Teste {index+1}")
        priority_raw = str(row.get("prioridade", default_priority)).lower().strip()
        priority_value = priority_map.get(priority_raw, default_priority)

        cenario_steps = row.get("cenario", [])
        if isinstance(cenario_steps, str):
            cenario_steps = [x.strip() for x in cenario_steps.split("\n") if x.strip()]
        if not isinstance(cenario_steps, list):
            cenario_steps = []

        # 1Ô∏èCabe√ßalho do Test Case
        writer.writerow(
            [
                "",  # ID vazio
                "Test Case",
                title,
                "1",
                "",
                "",
                priority_value,
                area_path,
                assigned_to,
                default_state,
            ]
        )

        step_counter = 2
        pending_quando = None

        # 2Ô∏è Passos Gherkin
        for step in cenario_steps:
            step_lower = step.lower().strip()

            if step_lower.startswith("dado"):
                writer.writerow(
                    ["", "", "", str(step_counter), step, "", "", "", "", ""]
                )
                step_counter += 1

            elif step_lower.startswith("quando"):
                pending_quando = step

            elif step_lower.startswith(("ent√£o", "entao")):
                writer.writerow(
                    [
                        "",
                        "",
                        "",
                        str(step_counter),
                        pending_quando or "",
                        step,
                        "",
                        "",
                        "",
                        "",
                    ]
                )
                pending_quando = None
                step_counter += 1

            elif step_lower.startswith("e "):
                if pending_quando:
                    writer.writerow(
                        ["", "", "", str(step_counter), step, "", "", "", "", ""]
                    )
                else:
                    writer.writerow(
                        ["", "", "", str(step_counter), "", step, "", "", "", ""]
                    )
                step_counter += 1

        # 3Ô∏èCaso tenha um 'Quando' sem 'Ent√£o'
        if pending_quando:
            writer.writerow(
                ["", "", "", str(step_counter), pending_quando, "", "", "", "", ""]
            )
            step_counter += 1

        # 4Ô∏è Linha em branco para separar Test Cases
        writer.writerow([])

    csv_bytes = buffer.getvalue().encode("utf-8-sig")
    buffer.close()
    return csv_bytes


# ==========================================================
#  Salva Gherkin ap√≥s edi√ß√£o do usu√°rio
# ==========================================================


def gerar_relatorio_md_dos_cenarios(df):
    """
    Gera texto Markdown consolidado com os cen√°rios Gherkin atuais.
    Cada linha do DataFrame vira um bloco Markdown formatado.
    """
    if df is None or df.empty:
        return "‚ö†Ô∏è Nenhum cen√°rio dispon√≠vel para gerar relat√≥rio."

    blocos = []
    for _, row in df.iterrows():
        titulo = row.get("titulo", "Sem t√≠tulo")
        prioridade = row.get("prioridade", "-")
        criterio = row.get("criterio_de_aceitacao_relacionado", "")
        cenario = row.get("cenario", "")

        bloco = f"""### üß© {titulo}
**Prioridade:** {prioridade}  
**Crit√©rio de Aceita√ß√£o:** {criterio}

```gherkin
{cenario.strip()}
```
"""
        blocos.append(bloco)
    return "\n".join(blocos)


# ==========================================================
#  EXPORTA√á√ÉO PARA XRAY (JIRA XRAY) - CSV
# ==========================================================


def gerar_csv_xray_from_df(
    df_original: pd.DataFrame,
    test_repository_folder: str,
    custom_fields: dict | None = None,
) -> bytes:
    """
    Gera um CSV 100% compat√≠vel com Xray (Jira Test Management).

    Formato requerido pelo Xray:
    - Summary: nome da atividade de teste
    - Description: descri√ß√£o do teste
    - Test_Repository_Folder: diret√≥rio onde o teste ser√° salvo (deve existir no Xray)
    - Test_Type: tipo de teste (sempre "Cucumber" para cen√°rios Gherkin)
    - Gherkin_Definition: cen√°rio de teste completo em formato Gherkin

    Campos opcionais/personalizados suportados:
    - Labels: etiquetas para categoriza√ß√£o
    - Priority: prioridade do teste (High, Medium, Low)
    - Component: componente do sistema relacionado
    - Assignee: respons√°vel pelo teste
    - Qualquer outro campo customizado do Jira

    Args:
        df_original: DataFrame com os cen√°rios de teste
        test_repository_folder: Diret√≥rio no Xray onde os testes ser√£o salvos
        custom_fields: Dicion√°rio com campos personalizados (ex: {"Labels": "QA,Automation", "Priority": "High"})

    Requisitos:
    - Separa√ß√£o por v√≠rgulas
    - Codifica√ß√£o UTF-8
    - Quebras de linha preservadas no campo Gherkin_Definition
    """

    # Campos obrigat√≥rios do Xray
    header = [
        "Summary",
        "Description",
        "Test_Repository_Folder",
        "Test_Type",
        "Gherkin_Definition",
    ]

    # Adiciona campos personalizados ao cabe√ßalho
    custom_fields = custom_fields or {}
    if custom_fields:
        header.extend(custom_fields.keys())

    buffer = io.StringIO()
    writer = csv.writer(buffer, delimiter=",", quoting=csv.QUOTE_ALL)
    writer.writerow(header)

    if df_original.empty:
        return buffer.getvalue().encode("utf-8")

    test_repository_folder = (test_repository_folder or "").strip()

    # Cada linha do DataFrame √© um caso de teste
    for index, row in df_original.iterrows():
        # Summary: usa o t√≠tulo do caso de teste
        summary = row.get("titulo", f"Caso de Teste {index+1}")

        # Description: combina crit√©rio de aceita√ß√£o e justificativa de acessibilidade
        criterio = row.get("criterio_de_aceitacao_relacionado", "")
        justificativa = row.get("justificativa_acessibilidade", "")

        description_parts = []
        if criterio:
            description_parts.append(f"Crit√©rio de Aceita√ß√£o: {criterio}")
        if justificativa:
            description_parts.append(
                f"Justificativa de Acessibilidade: {justificativa}"
            )

        description = (
            " | ".join(description_parts)
            if description_parts
            else "Teste gerado pelo QA Or√°culo"
        )

        # Test_Type: sempre "Cucumber"
        test_type = "Cucumber"

        # Gherkin_Definition: cen√°rio completo preservando quebras de linha
        cenario = row.get("cenario", "")
        if isinstance(cenario, list):
            gherkin_definition = "\n".join(cenario)
        else:
            gherkin_definition = str(cenario).strip()

        # Monta a linha com campos obrigat√≥rios
        row_data = [
            summary,
            description,
            test_repository_folder,
            test_type,
            gherkin_definition,
        ]

        # Adiciona valores dos campos personalizados
        if custom_fields:
            row_data.extend(custom_fields.values())

        # Escreve a linha no CSV
        writer.writerow(row_data)

    csv_bytes = buffer.getvalue().encode("utf-8")
    buffer.close()
    return csv_bytes
