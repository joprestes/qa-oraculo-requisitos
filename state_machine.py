# ==========================================================
# state_machine.py â€” MÃ¡quina de Estados do QA OrÃ¡culo
# ==========================================================
# ğŸ“˜ Define o ciclo de vida completo de uma anÃ¡lise de User Story
#    usando enums e dataclasses para garantir transiÃ§Ãµes seguras.
#
# ğŸ¯ PrincÃ­pios:
#   â€¢ Estado Ãºnico e previsÃ­vel
#   â€¢ TransiÃ§Ãµes explÃ­citas e validadas
#   â€¢ Imutabilidade onde possÃ­vel
#   â€¢ FÃ¡cil debug e testabilidade
# ==========================================================

from dataclasses import dataclass, field
from enum import Enum, auto

import pandas as pd


# ==========================================================
# ğŸ­ Estados PossÃ­veis da AnÃ¡lise
# ==========================================================
class AnalysisStage(Enum):
    """
    Estados vÃ¡lidos do fluxo de anÃ¡lise.

    TransiÃ§Ãµes vÃ¡lidas:
    INITIAL â†’ ANALYZING â†’ EDITING_ANALYSIS â†’ GENERATING_PLAN â†’ COMPLETED

    Qualquer estado pode ir para ERROR em caso de falha.
    """

    INITIAL = auto()  # Estado inicial (formulÃ¡rio vazio)
    ANALYZING = auto()  # IA estÃ¡ analisando a User Story
    EDITING_ANALYSIS = auto()  # UsuÃ¡rio estÃ¡ revisando/editando anÃ¡lise
    GENERATING_PLAN = auto()  # IA estÃ¡ gerando plano de testes
    COMPLETED = auto()  # AnÃ¡lise concluÃ­da (pronta para exportar)
    ERROR = auto()  # Erro crÃ­tico (permite retry)


# ==========================================================
# ğŸ“¦ Estado Global da AnÃ¡lise
# ==========================================================
@dataclass
class AnalysisState:
    """
    Representa o estado completo de uma anÃ¡lise em andamento.

    Attributes:
        stage: EstÃ¡gio atual do fluxo
        user_story: Texto da User Story original
        analysis_data: Dados estruturados da anÃ¡lise (JSON da IA)
        analysis_report: RelatÃ³rio formatado em Markdown
        test_plan_data: Casos de teste estruturados (lista de dicts)
        test_plan_report: Plano de testes em Markdown
        test_plan_df: DataFrame com casos de teste editÃ¡veis
        pdf_bytes: PDF gerado (bytes)
        saved_history_id: ID do registro no banco (None se nÃ£o salvo)
        error_message: Mensagem de erro (se stage == ERROR)
    """

    stage: AnalysisStage = AnalysisStage.INITIAL
    user_story: str = ""
    analysis_data: dict | None = None
    analysis_report: str = ""
    test_plan_data: dict | None = None
    test_plan_report: str = ""
    test_plan_df: pd.DataFrame | None = None
    pdf_bytes: bytes | None = None
    saved_history_id: int | None = None
    error_message: str = ""

    # Metadados internos (nÃ£o expostos na UI)
    _retry_count: int = field(default=0, repr=False)
    _last_updated: str | None = field(default=None, repr=False)

    # ==========================================================
    # ğŸ”’ ValidaÃ§Ãµes de TransiÃ§Ã£o
    # ==========================================================

    def can_start_analysis(self) -> bool:
        """Valida se pode iniciar anÃ¡lise (tem US e estÃ¡ no estado correto)"""
        return self.stage == AnalysisStage.INITIAL and self.user_story.strip() != ""

    def can_edit_analysis(self) -> bool:
        """Valida se pode editar anÃ¡lise (anÃ¡lise jÃ¡ foi gerada)"""
        return self.stage == AnalysisStage.ANALYZING and self.analysis_data is not None

    def can_generate_plan(self) -> bool:
        """Valida se pode gerar plano de testes (anÃ¡lise foi confirmada)"""
        return (
            self.stage == AnalysisStage.EDITING_ANALYSIS
            and self.analysis_data is not None
        )

    def can_export(self) -> bool:
        """Valida se pode exportar (anÃ¡lise estÃ¡ completa)"""
        return self.stage == AnalysisStage.COMPLETED

    def is_saved(self) -> bool:
        """Verifica se a anÃ¡lise jÃ¡ foi salva no histÃ³rico"""
        return self.saved_history_id is not None

    # ==========================================================
    # ğŸ”„ TransiÃ§Ãµes de Estado
    # ==========================================================

    def start_analysis(self):
        """Inicia anÃ¡lise da User Story"""
        if not self.can_start_analysis():
            raise ValueError(
                f"NÃ£o Ã© possÃ­vel iniciar anÃ¡lise no estado {self.stage.name}"
            )
        self.stage = AnalysisStage.ANALYZING
        self.error_message = ""

    def complete_analysis(self, analysis_data: dict, analysis_report: str):
        """Marca anÃ¡lise como concluÃ­da e pronta para ediÃ§Ã£o"""
        if self.stage != AnalysisStage.ANALYZING:
            raise ValueError(
                f"NÃ£o Ã© possÃ­vel completar anÃ¡lise no estado {self.stage.name}"
            )

        self.analysis_data = analysis_data
        self.analysis_report = analysis_report
        self.stage = AnalysisStage.EDITING_ANALYSIS

    def confirm_analysis_edits(self):
        """Confirma ediÃ§Ãµes da anÃ¡lise (mantÃ©m no mesmo estado)"""
        if not self.can_generate_plan():
            raise ValueError(
                f"NÃ£o Ã© possÃ­vel confirmar ediÃ§Ãµes no estado {self.stage.name}"
            )
        # Estado permanece EDITING_ANALYSIS atÃ© usuÃ¡rio pedir plano

    def start_plan_generation(self):
        """Inicia geraÃ§Ã£o do plano de testes"""
        if not self.can_generate_plan():
            raise ValueError(f"NÃ£o Ã© possÃ­vel gerar plano no estado {self.stage.name}")
        self.stage = AnalysisStage.GENERATING_PLAN

    def complete_plan_generation(
        self,
        test_plan_data: dict,
        test_plan_report: str,
        test_plan_df: pd.DataFrame,
        pdf_bytes: bytes,
    ):
        """Marca plano como concluÃ­do"""
        if self.stage != AnalysisStage.GENERATING_PLAN:
            raise ValueError(
                f"NÃ£o Ã© possÃ­vel completar plano no estado {self.stage.name}"
            )

        self.test_plan_data = test_plan_data
        self.test_plan_report = test_plan_report
        self.test_plan_df = test_plan_df
        self.pdf_bytes = pdf_bytes
        self.stage = AnalysisStage.COMPLETED

    def mark_as_saved(self, history_id: int):
        """Registra ID do histÃ³rico apÃ³s salvamento"""
        self.saved_history_id = history_id

    def set_error(self, error_message: str):
        """Marca estado como erro"""
        self.stage = AnalysisStage.ERROR
        self.error_message = error_message
        self._retry_count += 1

    def reset_for_retry(self):
        """Reseta para o estado anterior ao erro (permite retry)"""
        if self.stage != AnalysisStage.ERROR:
            raise ValueError("SÃ³ Ã© possÃ­vel fazer retry apÃ³s erro")

        # Volta para o Ãºltimo estado vÃ¡lido
        if self.analysis_data is None:
            self.stage = AnalysisStage.INITIAL
        elif self.test_plan_df is None:
            self.stage = AnalysisStage.EDITING_ANALYSIS
        else:
            self.stage = AnalysisStage.COMPLETED

        self.error_message = ""

    def reset_completely(self):
        """Reseta tudo para comeÃ§ar nova anÃ¡lise"""
        self.__init__()  # Reinicializa com valores padrÃ£o

    # ==========================================================
    # ğŸ” Helpers de InspeÃ§Ã£o
    # ==========================================================

    def get_progress_percentage(self) -> int:
        """Retorna progresso da anÃ¡lise (0-100%)"""
        progress_map = {
            AnalysisStage.INITIAL: 0,
            AnalysisStage.ANALYZING: 25,
            AnalysisStage.EDITING_ANALYSIS: 50,
            AnalysisStage.GENERATING_PLAN: 75,
            AnalysisStage.COMPLETED: 100,
            AnalysisStage.ERROR: 0,
        }
        return progress_map[self.stage]

    def get_stage_label(self) -> str:
        """Retorna label amigÃ¡vel do estÃ¡gio atual"""
        labels = {
            AnalysisStage.INITIAL: "Aguardando User Story",
            AnalysisStage.ANALYZING: "Analisando com IA...",
            AnalysisStage.EDITING_ANALYSIS: "RevisÃ£o e EdiÃ§Ã£o",
            AnalysisStage.GENERATING_PLAN: "Gerando Plano de Testes...",
            AnalysisStage.COMPLETED: "AnÃ¡lise ConcluÃ­da",
            AnalysisStage.ERROR: "Erro na ExecuÃ§Ã£o",
        }
        return labels[self.stage]

    def to_dict(self) -> dict:
        """Serializa estado para dicionÃ¡rio (Ãºtil para debug/logs)"""
        return {
            "stage": self.stage.name,
            "user_story_length": len(self.user_story),
            "has_analysis": self.analysis_data is not None,
            "has_plan": self.test_plan_df is not None,
            "is_saved": self.is_saved(),
            "progress": self.get_progress_percentage(),
        }


# ==========================================================
# ğŸ§ª Testes de ValidaÃ§Ã£o (executar com: python state_machine.py)
# ==========================================================
if __name__ == "__main__":
    print("ğŸ§ª Testando State Machine...\n")

    # Teste 1: Fluxo completo vÃ¡lido
    state = AnalysisState()
    state.user_story = "Como usuÃ¡rio, quero fazer login"

    assert state.can_start_analysis()
    state.start_analysis()
    assert state.stage == AnalysisStage.ANALYZING

    state.complete_analysis({"test": "data"}, "# RelatÃ³rio")
    assert state.can_generate_plan()

    state.start_plan_generation()
    state.complete_plan_generation({}, "", pd.DataFrame(), b"pdf")
    assert state.can_export()

    print("âœ… Teste 1: Fluxo completo vÃ¡lido - PASSOU")

    # Teste 2: TransiÃ§Ã£o invÃ¡lida deve falhar
    state2 = AnalysisState()
    try:
        state2.start_plan_generation()  # Sem anÃ¡lise
        print("âŒ Teste 2: FALHOU - Permitiu transiÃ§Ã£o invÃ¡lida")
    except ValueError:
        print("âœ… Teste 2: ValidaÃ§Ã£o de transiÃ§Ã£o - PASSOU")

    # Teste 3: Reset completo
    state.reset_completely()
    assert state.stage == AnalysisStage.INITIAL
    assert state.user_story == ""
    print("âœ… Teste 3: Reset completo - PASSOU")

    print("\nğŸ‰ Todos os testes passaram!")
