# ==========================================================
# QA Or√°culo - Configura√ß√£o de Ambiente
# ==========================================================
# Copie este arquivo para .env e configure as vari√°veis necess√°rias
# para o provedor LLM que voc√™ deseja utilizar.
#
# üìö Para mais informa√ß√µes, consulte: docs/LLM_CONFIG_GUIDE.md
# ==========================================================

# ==========================================================
# CONFIGURA√á√ÉO DO PROVEDOR LLM
# ==========================================================
# Define qual provedor de IA ser√° utilizado.
# Op√ß√µes dispon√≠veis: "google", "azure", "openai", "llama"
# Padr√£o: "google"
LLM_PROVIDER="google"

# Nome do modelo a ser utilizado (varia por provedor)
# Exemplos:
#   - Google: "gemini-2.0-flash-lite-001", "gemini-1.5-pro"
#   - Azure/OpenAI: "gpt-4", "gpt-3.5-turbo"
#   - Llama: "llama-3.1-8b", "llama-3.1-70b"
LLM_MODEL="gemini-2.0-flash-lite-001"

# ==========================================================
# GOOGLE GEMINI (Recomendado - Totalmente Suportado)
# ==========================================================
# Para usar o Google Gemini, configure:
# 1. LLM_PROVIDER="google"
# 2. LLM_MODEL="gemini-2.0-flash-lite-001" (ou outro modelo Gemini)
# 3. GOOGLE_API_KEY com sua chave da API
#
# üîë Obtenha sua chave em: https://makersuite.google.com/app/apikey
# ==========================================================
GOOGLE_API_KEY="sua_chave_google_aqui"

# Alternativa: usar LLM_API_KEY (funciona para qualquer provedor)
# LLM_API_KEY="sua_chave_google_aqui"

# ==========================================================
# AZURE OPENAI (Em Desenvolvimento)
# ==========================================================
# ‚ö†Ô∏è ATEN√á√ÉO: Integra√ß√£o com Azure OpenAI ainda n√£o est√° dispon√≠vel.
# As vari√°veis abaixo est√£o documentadas para refer√™ncia futura.
#
# Para usar Azure OpenAI quando dispon√≠vel, configure:
# 1. LLM_PROVIDER="azure"
# 2. LLM_MODEL="gpt-4" (ou seu deployment)
# 3. Vari√°veis abaixo
# ==========================================================
# AZURE_OPENAI_API_KEY="sua_chave_azure_aqui"
# AZURE_OPENAI_ENDPOINT="https://seu-recurso.openai.azure.com/"
# AZURE_OPENAI_DEPLOYMENT="nome-do-seu-deployment"
# AZURE_OPENAI_API_VERSION="2024-02-15-preview"

# ==========================================================
# OPENAI GPT (Em Desenvolvimento)
# ==========================================================
# ‚ö†Ô∏è ATEN√á√ÉO: Integra√ß√£o com OpenAI GPT ainda n√£o est√° dispon√≠vel.
# As vari√°veis abaixo est√£o documentadas para refer√™ncia futura.
#
# Para usar OpenAI GPT quando dispon√≠vel, configure:
# 1. LLM_PROVIDER="openai"
# 2. LLM_MODEL="gpt-4" (ou outro modelo OpenAI)
# 3. OPENAI_API_KEY com sua chave
# ==========================================================
# OPENAI_API_KEY="sua_chave_openai_aqui"

# Opcional: URL base customizada (para proxies ou endpoints alternativos)
# OPENAI_BASE_URL="https://api.openai.com/v1"

# Opcional: ID da organiza√ß√£o OpenAI
# OPENAI_ORGANIZATION="org-xxxxxxxxxxxxxxxx"

# ==========================================================
# LLAMA (Meta) (Em Desenvolvimento)
# ==========================================================
# ‚ö†Ô∏è ATEN√á√ÉO: Integra√ß√£o com LLaMA ainda n√£o est√° dispon√≠vel.
# As vari√°veis abaixo est√£o documentadas para refer√™ncia futura.
#
# Para usar LLaMA quando dispon√≠vel, configure:
# 1. LLM_PROVIDER="llama"
# 2. LLM_MODEL="llama-3.1-8b" (ou outro modelo)
# 3. Vari√°veis abaixo
# ==========================================================
# LLAMA_API_KEY="sua_chave_llama_aqui"
# LLAMA_ENDPOINT="https://api.llama.meta.com/v1"
# LLAMA_PROJECT_ID="seu_project_id"

# ==========================================================
# CONFIGURA√á√ïES ADICIONAIS (Opcional)
# ==========================================================
# Estas configura√ß√µes s√£o opcionais e possuem valores padr√£o.

# Caminho do banco de dados SQLite (padr√£o: data/qa_oraculo_history.db)
# DB_PATH="data/qa_oraculo_history.db"

# N√≠vel de log (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# LOG_LEVEL="INFO"

# ==========================================================
# INSTRU√á√ïES DE USO
# ==========================================================
# 1. Copie este arquivo: cp .env.example .env
# 2. Edite o arquivo .env com suas credenciais
# 3. Escolha um provedor LLM (recomendado: "google")
# 4. Configure as vari√°veis correspondentes
# 5. Execute: streamlit run main.py
#
# üìñ Documenta√ß√£o completa: docs/SETUP_GUIDE.md
# üîß Guia de LLMs: docs/LLM_CONFIG_GUIDE.md
# ==========================================================