<p align="center">
  <img src="assets/logo_oraculo.png" alt="QA Oracle Logo" width="200"/>
</p>

<h1 align="center">ğŸ”® QA Oracle</h1>
<p align="center"><i>Requirements Analysis with Artificial Intelligence</i></p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.11+-blue.svg"/>
  <img src="https://img.shields.io/badge/license-MIT-green.svg"/>
  <img src="https://img.shields.io/badge/Streamlit-App-red.svg"/>
  <img src="https://img.shields.io/badge/code%20style-black-000000.svg"/>
</p>

<nav aria-label="Language switcher" style="text-align: right;">
<a href="README-en.md" aria-current="page">ğŸ‡ºğŸ‡¸ <strong>English</strong></a> |
<a href="README.md">ğŸ‡§ğŸ‡· PortuguÃªs</a>
</nav>

## ğŸš€ Why use QA Oracle?

Tired of **vague User Stories** and **endless meetings** to align understanding?

**QA Oracle** transforms scattered requirements into **ready-to-test specifications** using cutting-edge AI.

ğŸ‘‰ In just **minutes**, youâ€™ll have:
- âœ… Clear acceptance criteria  
- â“ Smart questions for the PO  
- ğŸ“ Complete and well-structured test plans  
- ğŸ§ª On-demand Gherkin scenarios  
- ğŸ“„ Exportable reports (.md, .pdf, .xlsx)  

Itâ€™s like having a **Senior QA available 24/7**, accelerating planning and preventing failures even before the first bug appears.

---

## ğŸ“¸ Interface Preview

![alt text](assets/qa_oraculo_cartoon_demo.gif)

---

## ğŸš€ Main Features

- ğŸ’» **Interactive Web Interface** built with **Streamlit**.  
- ğŸ“ **Editable and Interactive Analysis:** <!-- NEW --> After the AI generates the initial analysis, the application displays an editable form. The user can refine, correct, and add information (acceptance criteria, risks, etc.) before proceeding, ensuring that the final test plan is based on requirements validated by a human.  
- ğŸ” **Ambiguity Detection** and smart questions for the PO.  
- âœ… **Acceptance Criteria Generation** that are clear and verifiable.  
- ğŸ“Š **Test Case Table** interactive and sortable.  
- ğŸ“¥ **Multiple Export Options** (`.md`, `.pdf`, Azure and Jira).  
- ğŸ—ï¸ **Modular, Optimized, and 100% Tested Code.**  

---

## ğŸ› ï¸ Technologies Used

- ğŸ Python 3.11+  
- ğŸŒ Streamlit (Web UI Framework)  
- ğŸ§  LangGraph & Google Gemini (AI orchestration)  
- ğŸ“Š Pandas (Data handling)  
- ğŸ“„ FPDF2 (PDF report generation)  
- ğŸ“ˆ Openpyxl (Excel .xlsx file handling)  

---

## âš™ï¸ How to Run Locally

<details>
<summary><b>ğŸ“Œ Prerequisites</b></summary>

- Python 3.11+  
- Google API Key (get it [here](https://console.cloud.google.com))  

</details>

<details>
<summary><b>ğŸš€ Installation</b></summary>

```bash
# Clone the repository
git clone https://github.com/joprestes/qa-oraculo-requisitos.git
cd qa-oraculo-requisitos

# Create and activate the virtual environment
python3 -m venv venv
source venv/bin/activate  # Mac/Linux
# .\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```
</details>

<details>
<summary><b>ğŸ”‘ API Configuration</b></summary>

Create a `.env` file in the project root:

```env
GOOGLE_API_KEY="your_api_key_here"
```
</details>

<details>
<summary><b>â–¶ï¸ Run</b></summary>

```bash
streamlit run app.py
```

ğŸ‰ QA Oracle will automatically open in your browser!
</details>

---

### ğŸ“‹ How to Use

1. **Insert the User Story:** Paste the US you want to analyze.  
2. **Start the Analysis:** Click â€œAnalyze User Storyâ€ for the AI to generate the initial quality analysis.  
3. **Refine the Analysis (Collaboration Step):** The application will display a pre-filled form with the AIâ€™s analysis. Review, edit the fields as needed, and click â€œSave Analysis and Continue.â€  
4. **Choose Next Step:** With the refined and saved analysis, decide whether to generate a detailed test plan or finish.  
5. **Export Results:** Use the download buttons to get artifacts in multiple formats. For Azure and Jira, fill in the customizable fields.  
6. **Start Again:** Click â€œStart New Analysisâ€ to clear the screen.  

---

## ğŸ¤” Troubleshooting

âŒ **Error:** Invalid API Key  
âœ”ï¸ Make sure the `.env` file is in the root folder and the â€œGenerative Languageâ€ API is enabled in Google Cloud.  

âŒ **Error:** `streamlit` command not found  
âœ”ï¸ Make sure the virtual environment `venv` is activated.  

---

## ğŸ§ª Quality and Testing

The quality of this project is ensured by a robust unit test suite built with `pytest`, validating the logic of the `graph.py` and `utils.py` modules.

- **Test Coverage**: Critical logic modules reached **100% line coverage**, ensuring high reliability and safety for future changes.  
- **Run Tests**:  
  ```bash
  pytest
  ```

- **Coverage Verification**:  
  ```bash
  pytest --cov=graph --cov=utils
  ```

---

## ğŸ“Œ Roadmap

- [x] Interactive web interface with Streamlit  
- [x] Generation of acceptance criteria and PO questions  
- [x] On-demand complete test plan generation  
- [x] Report export in `.md` and `.pdf`  
- [x] Export to Azure DevOps (`.xlsx`)  
- [x] Export to Jira Zephyr (`.xlsx`)  
- [x] Code refactoring to modular architecture  
- [x] Implement caching to optimize API calls  
- [x] Centralize prompts in configuration files  
- [x] Test suite implementation with `pytest` (100% coverage)  
- [x] Allow interactive editing of initial analysis by user 
- [ ] Add analysis history in session  
- [ ] Containerize application with Docker  

---

## ğŸ¤ Contribution

Contributions are very welcome!  
- Open an **issue** to report bugs or suggest improvements  
- Send a **Pull Request** with new features  

â­ If this project helped you, donâ€™t forget to leave a **star on the repository**!
