# ============================================================
# ğŸ“˜ test/test_utils.py â€” Testes de unidade do mÃ³dulo utils
# ============================================================
# Este arquivo contÃ©m testes de unidade que validam o comportamento
# das funÃ§Ãµes utilitÃ¡rias do projeto QA OrÃ¡culo.
#
# Nesta seÃ§Ã£o, testamos as funÃ§Ãµes fundamentais relacionadas a:
#   - NormalizaÃ§Ã£o de strings
#   - Busca flexÃ­vel de chaves em dicionÃ¡rios
#   - PreparaÃ§Ã£o de dados para exportaÃ§Ã£o (Zephyr e Excel)
#   - GeraÃ§Ã£o de nomes de arquivos seguros
#
# Cada teste aqui garante que as funÃ§Ãµes utilitÃ¡rias mantenham
# a consistÃªncia e robustez da aplicaÃ§Ã£o em operaÃ§Ãµes bÃ¡sicas.
# ============================================================

import datetime
import io
import locale
import unittest
from io import BytesIO
from unittest.mock import patch

import pandas as pd
import pytest

import utils
from app import _ensure_bytes
from utils import (
    clean_markdown_report,
    gerar_nome_arquivo_seguro,
    gerar_relatorio_md_dos_cenarios,
    get_flexible,
    normalizar_string,
    parse_json_strict,
    preparar_df_para_zephyr_xlsx,
    to_excel,
)

#  VariÃ¡veis globais para testes de CSV Azure

EXPECTED_COLUMNS_COUNT = 10
EXPECTED_TEST_CASES_COUNT = 2
MAX_FILENAME_BASE = 50

# ============================================================
#  Testes gerais de funÃ§Ãµes utilitÃ¡rias
# ============================================================
# Esta classe agrupa os testes principais das funÃ§Ãµes utilitÃ¡rias.
# Ela cobre os comportamentos de transformaÃ§Ã£o de dados,
# manipulaÃ§Ã£o de texto e exportaÃ§Ã£o de planilhas.
# ============================================================


class TestUtilsFunctions(unittest.TestCase):
    """Classe que testa as principais funÃ§Ãµes do mÃ³dulo utils."""

    def setUp(self):
        """
         Executa antes de cada teste.
        Cria um DataFrame de exemplo que simula dois casos de teste:
        - Um cenÃ¡rio â€œfelizâ€ (fluxo principal)
        - Um cenÃ¡rio â€œinfelizâ€ (erro ou exceÃ§Ã£o esperada)
        """
        self.sample_df = pd.DataFrame(
            [
                {
                    "titulo": "Caminho Feliz",
                    "prioridade": "alta",
                    "cenario": "Passo 1\nPasso 2",
                },
                {
                    "titulo": "Caminho Infeliz",
                    "prioridade": "mÃ©dia",
                    "cenario": "Passo A",
                },
            ]
        )

    def test_normalizar_string(self):
        """
         Verifica se caracteres acentuados e cedilhas sÃ£o convertidos
        para suas versÃµes sem acentuaÃ§Ã£o.
        Exemplo: 'usuÃ¡rio' â†’ 'usuario', 'Ã§' â†’ 'c'
        """
        self.assertEqual(
            normalizar_string("usuÃ¡rio e relatÃ³rio com Ã§ e Ã£"),
            "usuario e relatorio com c e a",
        )

    def test_get_flexible(self):
        """
         Garante que a funÃ§Ã£o `get_flexible` consegue encontrar
        chaves alternativas em dicionÃ¡rios com diferentes nomes de campos.
        Inclui validaÃ§Ã£o de fallback e tipos invÃ¡lidos.
        """
        data = {"avaliacao_geral": "Bom", "riscos": ["Risco 1"]}

        #  Caso 1 â€” Encontra a chave primÃ¡ria
        self.assertEqual(
            get_flexible(data, ["avaliacao_geral", "avaliacao"], "PadrÃ£o"), "Bom"
        )

        #  Caso 2 â€” Encontra a chave alternativa
        self.assertEqual(
            get_flexible(data, ["riscos_e_dependencias", "riscos"], []), ["Risco 1"]
        )

        #  Caso 3 â€” Nenhuma chave encontrada (retorna valor padrÃ£o)
        self.assertEqual(
            get_flexible(data, ["pontos_ambiguos", "ambiguidades"], []), []
        )

        #  Caso 4 â€” Entrada invÃ¡lida (nÃ£o Ã© dict)
        self.assertEqual(get_flexible(None, ["chave"], "PadrÃ£o"), "PadrÃ£o")
        self.assertEqual(get_flexible([], ["chave"], "PadrÃ£o"), "PadrÃ£o")

    def test_preparar_df_para_zephyr_xlsx(self):
        """
         Testa se a funÃ§Ã£o converte corretamente um DataFrame de cenÃ¡rios
        para o formato esperado pelo Jira Zephyr (planilha de importaÃ§Ã£o).
        Espera-se que o nÃºmero de linhas exportadas seja igual ao nÃºmero
        de casos de teste + cabeÃ§alho.
        """
        df_zephyr = preparar_df_para_zephyr_xlsx(self.sample_df, "High", "s1", "Desc")
        self.assertEqual(len(df_zephyr), 3)

    @patch("utils.datetime")
    def test_gerar_nome_arquivo_seguro(self, mock_datetime):
        """
        Garante que o nome de arquivo gerado:
          - Remove caracteres especiais
          - Inclui timestamp de data/hora
          - Usa o padrÃ£o `relatorio_qa_oraculo` quando o nome estiver vazio
        """
        #  Define uma data fixa para prever o resultado
        mock_now = datetime.datetime(2024, 1, 1, 12, 0, 0)
        mock_datetime.datetime.now.return_value = mock_now

        # Testa geraÃ§Ã£o com nome customizado
        self.assertEqual(
            gerar_nome_arquivo_seguro("usuÃ¡rio", "txt"), "usuario_20240101_120000.txt"
        )

        # Testa fallback padrÃ£o (sem nome)
        self.assertEqual(gerar_nome_arquivo_seguro("", "md"), "relatorio_qa_oraculo.md")

    def test_to_excel_conversion(self):
        """
        Garante a integridade da funÃ§Ã£o `to_excel`, verificando se:
          1ï¸ O DataFrame Ã© convertido para bytes.
          2ï¸O arquivo pode ser reaberto e contÃ©m os mesmos dados originais.
        """
        source_df = pd.DataFrame({"ID": [1, 2], "Nome": ["Teste A", "Teste B"]})
        sheet_name = "MinhaPlanilha"

        #  Converte DataFrame â†’ Excel (em bytes)
        excel_bytes = to_excel(source_df, sheet_name)

        #  Deve retornar bytes vÃ¡lidos
        self.assertIsInstance(excel_bytes, bytes)
        self.assertTrue(len(excel_bytes) > 0)

        #  Converte de volta para DataFrame e compara os dados
        result_df = pd.read_excel(io.BytesIO(excel_bytes), sheet_name=sheet_name)
        pd.testing.assert_frame_equal(source_df, result_df)


# ============================================================
#  Testes extras â€” Markdown, JSON e _ensure_bytes
# ============================================================
# Esta seÃ§Ã£o valida funÃ§Ãµes auxiliares do mÃ³dulo utils,
# responsÃ¡veis por:
#   - Limpar relatÃ³rios em Markdown removendo cercas de cÃ³digo
#   - Fazer parsing seguro de JSON retornado por IA (com e sem cercas)
#   - Converter objetos em bytes de forma resiliente
#
# Esses testes sÃ£o importantes pois garantem robustez na
# manipulaÃ§Ã£o de texto, exportaÃ§Ã£o e comunicaÃ§Ã£o entre mÃ³dulos.
# ============================================================


class TestUtilsExtras(unittest.TestCase):
    """Testa funÃ§Ãµes auxiliares de limpeza e parsing do mÃ³dulo utils."""

    def test_clean_markdown_report_completo(self):
        """
        Garante que o texto entre cercas ```markdown e ``` seja extraÃ­do corretamente.
        O conteÃºdo fora dessas marcaÃ§Ãµes deve ser removido.
        """
        texto = "```markdown\n# TÃ­tulo\n```"
        esperado = "# TÃ­tulo"
        self.assertEqual(clean_markdown_report(texto), esperado)

    def test_clean_markdown_report_sem_cercas(self):
        """
         Verifica o comportamento quando o texto nÃ£o contÃ©m cercas de markdown.
        Nesse caso, o conteÃºdo deve ser retornado inalterado.
        """
        texto = "# Apenas texto normal"
        self.assertEqual(clean_markdown_report(texto), "# Apenas texto normal")

    def test_clean_markdown_report_nao_string(self):
        """
        Se o valor passado nÃ£o for uma string (ex: None),
        a funÃ§Ã£o deve retornar uma string vazia, evitando exceÃ§Ãµes.
        """
        self.assertEqual(clean_markdown_report(None), "")

    def test_parse_json_strict_valido(self):
        """
         Testa o parsing de um JSON puro, sem formataÃ§Ã£o adicional.
        O resultado deve ser um dicionÃ¡rio Python equivalente.
        """
        texto = '{"key": "value"}'
        self.assertEqual(parse_json_strict(texto), {"key": "value"})

    def test_parse_json_strict_com_cercas(self):
        """
         Valida o comportamento com JSONs delimitados por ```json ... ```.
        A funÃ§Ã£o deve ignorar as cercas e decodificar o conteÃºdo corretamente.
        """
        texto = '```json\n{"key": "value"}\n```'
        self.assertEqual(parse_json_strict(texto), {"key": "value"})

    def test_parse_json_strict_invalido(self):
        """
         Quando o texto nÃ£o Ã© JSON vÃ¡lido, a funÃ§Ã£o deve lanÃ§ar ValueError,
        mantendo a robustez contra entradas inesperadas.
        """
        with self.assertRaises(ValueError):
            parse_json_strict("nÃ£o Ã© json")


def test_gerar_relatorio_md_dos_cenarios_completo():
    """
    Valida a funÃ§Ã£o `gerar_relatorio_md_dos_cenarios`, garantindo que:
      - Gere texto Markdown com blocos Gherkin
      - Inclua os campos principais de cada caso de teste
      - Trate corretamente DataFrames vazios
    """
    df = pd.DataFrame(
        [
            {
                "titulo": "Login vÃ¡lido",
                "prioridade": "Alta",
                "criterio_de_aceitacao_relacionado": "UsuÃ¡rio faz login com sucesso",
                "cenario": "CenÃ¡rio: Login vÃ¡lido\nDado que o usuÃ¡rio acessa\nQuando insere credenciais\nEntÃ£o o login Ã© bem-sucedido",
            },
            {
                "titulo": "Login invÃ¡lido",
                "prioridade": "Baixa",
                "criterio_de_aceitacao_relacionado": "UsuÃ¡rio insere senha incorreta",
                "cenario": "CenÃ¡rio: Login invÃ¡lido\nDado que o usuÃ¡rio acessa\nQuando insere senha errada\nEntÃ£o deve ver mensagem de erro",
            },
        ]
    )

    md = gerar_relatorio_md_dos_cenarios(df)

    # Deve conter seÃ§Ãµes Markdown formatadas corretamente
    assert "### ğŸ§© Login vÃ¡lido" in md
    assert "### ğŸ§© Login invÃ¡lido" in md
    assert "```gherkin" in md
    assert "Dado que o usuÃ¡rio acessa" in md

    # Mesmo DF vazio deve retornar texto padrÃ£o, nÃ£o erro
    vazio = pd.DataFrame()
    vazio_md = gerar_relatorio_md_dos_cenarios(vazio)
    assert "Nenhum cenÃ¡rio disponÃ­vel" in vazio_md


# ============================================================
#  Testes complementares independentes
# ============================================================
# Estes testes nÃ£o fazem parte da classe acima, mas cobrem
# variaÃ§Ãµes e exceÃ§Ãµes adicionais, garantindo cobertura total
# do mÃ³dulo e de comportamentos extremos.
# ============================================================


def test_parse_json_strict_com_cercas_incompletas():
    """
     Cobre o caso em que hÃ¡ apenas a abertura das cercas ```json,
    mas sem o fechamento final. A funÃ§Ã£o deve conseguir parsear o conteÃºdo.
    """
    texto = '```json\n{"key": "value"}'
    assert utils.parse_json_strict(texto) == {"key": "value"}


def test_parse_json_strict_invalido_levanta():
    """
     Caso o conteÃºdo seja ilegÃ­vel como JSON, o mÃ©todo
    deve lanÃ§ar uma exceÃ§Ã£o ValueError, indicando falha no parsing.
    """
    with pytest.raises(ValueError):
        utils.parse_json_strict("nÃ£o Ã© json vÃ¡lido")


def test_gerar_nome_arquivo_seguro_caracteres_invalidos():
    """
     Garante que caracteres invÃ¡lidos em nomes de arquivo
    (como /, :, *, ?) sejam removidos e que a extensÃ£o final seja mantida.
    """
    nome = gerar_nome_arquivo_seguro("HistÃ³ria/InvÃ¡lida:*?", "txt")
    assert nome.endswith(".txt")
    assert "/" not in nome and ":" not in nome


def test_to_excel_dataframe_vazio():
    """
     Mesmo um DataFrame vazio deve gerar um arquivo Excel vÃ¡lido.
    A funÃ§Ã£o deve retornar um buffer de bytes, nÃ£o lanÃ§ar exceÃ§Ã£o.
    """
    df = pd.DataFrame()
    buf = to_excel(df, sheet_name="Vazio")
    assert isinstance(buf, (bytes | bytearray))


def test_ensure_bytes_com_getvalue():
    """
     Testa a funÃ§Ã£o `_ensure_bytes` com objetos que possuem
    o mÃ©todo `getvalue()`, como `BytesIO`.
    O retorno deve ser exatamente o conteÃºdo em bytes.
    """
    obj = BytesIO(b"dados em bytes")
    assert _ensure_bytes(obj) == b"dados em bytes"


def test_ensure_bytes_com_bytes_diretos():
    """
     Verifica o comportamento de `_ensure_bytes` quando recebe
    diretamente valores jÃ¡ em bytes ou bytearray.
    A funÃ§Ã£o deve apenas retornÃ¡-los sem modificaÃ§Ãµes.
    """
    assert _ensure_bytes(b"ja sou bytes") == b"ja sou bytes"
    assert _ensure_bytes(bytearray(b"sou bytearray")) == b"sou bytearray"


# ============================================================
#  TESTES â€” gerar_csv_azure_from_df
# ============================================================


def test_gerar_csv_azure_from_df_basico(monkeypatch):
    """Valida estrutura, separador e ID vazio (locale PT-BR)."""
    df = pd.DataFrame(
        [
            {
                "titulo": "Login VÃ¡lido",
                "prioridade": "Alta",
                "cenario": "Dado que o usuÃ¡rio acessa\nQuando insere credenciais\nEntÃ£o o login Ã© bem-sucedido",
            }
        ]
    )

    monkeypatch.setattr(locale, "getlocale", lambda: ("pt_BR", "UTF-8"))
    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area/Teste", "QA Tester")
    csv_text = csv_bytes.decode("utf-8-sig")
    linhas = [linha for linha in csv_text.splitlines() if linha.strip()]

    # CabeÃ§alho correto
    assert linhas[0].startswith("ID;Work Item Type;Title;Test Step;")
    # Cada linha tem 10 colunas
    for linha in linhas[1:]:
        campos = linha.split(";")
        assert len(campos) == EXPECTED_COLUMNS_COUNT
    # ID vazio
    assert linhas[1].split(";")[0] == ""


def test_gerar_csv_azure_from_df_locale_en(monkeypatch):
    """Garante que o separador mude para vÃ­rgula em EN-US."""
    df = pd.DataFrame(
        [
            {
                "titulo": "Cadastro UsuÃ¡rio",
                "prioridade": "Low",
                "cenario": "Dado que o usuÃ¡rio abre o app\nEntÃ£o vÃª a tela inicial",
            },
        ]
    )

    monkeypatch.setattr(locale, "getlocale", lambda: ("en_US", "UTF-8"))
    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area/EN", "QA EN")
    csv_text = csv_bytes.decode("utf-8-sig")
    header = csv_text.splitlines()[0]

    assert "," in header
    assert ";" not in header


def test_gerar_csv_azure_from_df_vazio():
    """Garante que DataFrame vazio gera apenas cabeÃ§alho."""
    df_vazio = pd.DataFrame()
    csv_bytes = utils.gerar_csv_azure_from_df(df_vazio, "", "")
    csv_text = csv_bytes.decode("utf-8-sig").strip()
    linhas = csv_text.splitlines()

    assert len(linhas) == 1
    assert "Work Item Type" in linhas[0]
    assert linhas[0].startswith("ID")


def test_gerar_csv_azure_from_df_multiplos_casos(monkeypatch):
    """Cada linha do DF deve gerar um Test Case separado."""
    df = pd.DataFrame(
        [
            {
                "titulo": "CT 1",
                "prioridade": "Alta",
                "cenario": "Dado passo 1\nEntÃ£o ok",
            },
            {
                "titulo": "CT 2",
                "prioridade": "Baixa",
                "cenario": "Dado passo 2\nEntÃ£o outro ok",
            },
        ]
    )

    monkeypatch.setattr(locale, "getlocale", lambda: ("pt_BR", "UTF-8"))
    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area", "QA")
    csv_text = csv_bytes.decode("utf-8-sig")
    linhas = [linha for linha in csv_text.splitlines() if "Test Case" in linha]

    assert len(linhas) == EXPECTED_TEST_CASES_COUNT


def test_normalizar_string_vazia_ou_none():
    assert utils.normalizar_string("") == ""
    assert utils.normalizar_string("Ã¡Ã©Ã­Ã³Ãº") == "aeiou"
    # None deve levantar AttributeError (pois nÃ£o Ã© string)
    with pytest.raises(TypeError):
        utils.normalizar_string(None)


def test_gerar_nome_arquivo_seguro_truncamento():
    us = "HistÃ³ria muito longa " * 10  # cria um nome >50 chars
    nome = utils.gerar_nome_arquivo_seguro(us, "csv")
    assert nome.endswith(".csv")
    # o nome base deve ter no mÃ¡ximo 50 caracteres antes do timestamp
    assert len(nome.split("_")[0]) <= MAX_FILENAME_BASE


def test_parse_json_strict_lixo_ao_redor():
    """
    Garante que parse_json_strict lanÃ§a ValueError quando
    o texto contÃ©m lixo antes ou depois das cercas de cÃ³digo.
    Isso cobre o ramo de exceÃ§Ã£o (json.JSONDecodeError).
    """
    texto = 'inÃ­cio```json\n{"ok": true}\n```fim'
    with pytest.raises(ValueError):
        utils.parse_json_strict(texto)


def test_clean_markdown_report_cercas_incompletas():
    texto = "```markdown\n# TÃ­tulo sem fechamento"
    result = utils.clean_markdown_report(texto)
    assert "# TÃ­tulo" in result


def test_gerar_csv_azure_df_vazio_e_prioridade_invalida():
    df_vazio = pd.DataFrame()
    csv_bytes = utils.gerar_csv_azure_from_df(df_vazio, "Area", "Dev")
    assert b"Work Item Type" in csv_bytes  # sÃ³ header

    df_invalida = pd.DataFrame(
        [{"titulo": "CT", "cenario": "Dado algo", "prioridade": "urgente"}]
    )
    csv_bytes2 = utils.gerar_csv_azure_from_df(df_invalida, "Area", "Dev")
    text = csv_bytes2.decode("utf-8-sig")
    # deve cair no default_priority ("2")
    assert ";2;" in text or ",2," in text


# ============================================================
#  Testes complementares â€”
# ============================================================
# Esta seÃ§Ã£o garante a cobertura completa do mÃ³dulo utils.
# SÃ£o incluÃ­dos testes de exceÃ§Ãµes, fluxos alternativos e
# comportamentos de borda. O objetivo Ã© validar que todas
# as ramificaÃ§Ãµes lÃ³gicas das funÃ§Ãµes sejam exercitadas.
# ============================================================


def test_ensure_bytes_tipo_invalido():
    """
     ForÃ§a `_ensure_bytes` a lidar com tipos inesperados (int, dict).
    A funÃ§Ã£o deve converter qualquer tipo nÃ£o suportado em bytes
    chamando `str()` internamente.
    """
    assert _ensure_bytes(123) == b"123"
    # Para dicionÃ¡rios, o retorno deve conter o caractere â€œ{â€
    assert b"{" in _ensure_bytes({"a": 1})


def test_clean_markdown_report_com_fechamento_de_cercas():
    """
     Verifica se a funÃ§Ã£o `clean_markdown_report` remove corretamente
    o fechamento de cercas de cÃ³digo (```), mantendo apenas o conteÃºdo.
    """
    texto = "# TÃ­tulo\n```"
    result = utils.clean_markdown_report(texto)
    assert "```" not in result


def test_parse_json_strict_apenas_inicio_com_cercas():
    """
     Garante a cobertura do caso em que o JSON contÃ©m apenas
    a abertura das cercas (` ```json `) mas sem o fechamento final.
    O conteÃºdo interno ainda deve ser interpretado corretamente.
    """
    texto = '```json\n{"a": 1}'
    result = utils.parse_json_strict(texto)
    assert result == {"a": 1}


def test_parse_json_strict_apenas_fim_com_cercas():
    """
     Garante a cobertura do caso inverso: o JSON termina com as cercas
    de fechamento ``` mas nÃ£o tem abertura. A funÃ§Ã£o deve conseguir
    decodificar normalmente o conteÃºdo.
    """
    texto = '{"b": 2}\n```'
    result = utils.parse_json_strict(texto)
    assert result == {"b": 2}


def test_gerar_csv_azure_locale_invalido(monkeypatch):
    """
     ForÃ§a uma exceÃ§Ã£o na detecÃ§Ã£o do locale para garantir que
    a funÃ§Ã£o `gerar_csv_azure_from_df` utilize o fallback padrÃ£o.
    Mesmo sem locale vÃ¡lido, o CSV deve ser gerado corretamente.
    """
    df = pd.DataFrame([{"titulo": "CT", "cenario": "Quando faÃ§o algo"}])

    # Simula falha no locale.getlocale()
    monkeypatch.setattr("locale.getlocale", lambda: (None, None))

    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area", "QA")

    #  Ainda deve retornar um arquivo vÃ¡lido
    assert isinstance(csv_bytes, (bytes | bytearray))
    assert b"Test Case" in csv_bytes


def test_to_excel_erro_salvar(monkeypatch):
    """
     ForÃ§a um erro interno no salvamento do Excel para cobrir o bloco `except`.
    Garante que o erro seja propagado corretamente como ValueError.
    """

    df = pd.DataFrame({"A": [1]})

    # Classe fictÃ­cia que simula uma falha ao salvar o arquivo
    class DummyWriter:
        def __enter__(self):
            return self

        def __exit__(self, *a):
            pass

        def save(self):
            raise ValueError("Erro simulado")

    # Substitui o ExcelWriter do pandas pela classe DummyWriter
    monkeypatch.setattr("pandas.ExcelWriter", lambda *a, **k: DummyWriter())

    with pytest.raises(ValueError):
        utils.to_excel(df, "Sheet1")


def test_clean_markdown_report_final_com_cercas():
    """
     Cobre o uso do `re.sub` interno que remove as cercas finais.
    O conteÃºdo deve permanecer limpo e sem marcas de ``` no final.
    """
    texto = "# TÃ­tulo\n```"
    result = utils.clean_markdown_report(texto)
    assert "```" not in result
    assert "# TÃ­tulo" in result


def test_gerar_csv_azure_quando_sem_entao():
    """
     Cobre o cenÃ¡rio em que existe um passo 'Quando' mas nÃ£o hÃ¡
    passo 'EntÃ£o'. O CSV ainda deve ser gerado e conter o passo Ãºnico.
    """
    df = pd.DataFrame(
        [{"titulo": "CT incompleto", "cenario": ["Quando clico no botÃ£o"]}]
    )

    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area", "QA")
    text = csv_bytes.decode("utf-8-sig")

    #  Deve conter o passo 'Quando' no conteÃºdo final
    assert "Quando clico no botÃ£o" in text


def test_preparar_df_para_zephyr_cenario_vazio_cobre_continue():
    """
     Cobre o ramo da linha 96 em `preparar_df_para_zephyr_xlsx`:
    `if not cenario_steps: continue`
    Garante que cenÃ¡rios vazios (string vazia ou None) sejam ignorados
    sem gerar erro ou linha indevida no resultado.
    """
    df = pd.DataFrame(
        [
            {"titulo": "CT sem passos", "cenario": ""},
            {"titulo": "CT None", "cenario": None},
        ]
    )

    result = utils.preparar_df_para_zephyr_xlsx(df, "High", "QA", "Desc")

    #  Nenhum cenÃ¡rio vÃ¡lido â†’ resultado vazio
    assert result.empty


def test_gerar_csv_azure_cenario_tipo_invalido_cobre_linha_227():
    """
     Cobre o trecho da linha 227 de `gerar_csv_azure_from_df`:
    `if not isinstance(cenario_steps, list)`
    Garante que valores de cenÃ¡rio nÃ£o-lista (como inteiros) sejam
    tratados de forma segura, sem lanÃ§ar erro.
    """
    df = pd.DataFrame(
        [{"titulo": "CT tipo invÃ¡lido", "prioridade": "baixa", "cenario": 123}]
    )

    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area/Teste", "QA")
    text = csv_bytes.decode("utf-8-sig")

    #  O tÃ­tulo deve existir, mas sem passos (cenÃ¡rio ignorado)
    assert "CT tipo invÃ¡lido" in text
    assert "Dado" not in text and "Quando" not in text


def test_gerar_csv_azure_com_passos_com_e_cobre_279_288():
    """
     Cobre o bloco das linhas 279-288 em `gerar_csv_azure_from_df`,
    que trata passos comeÃ§ando com 'E ' (continuaÃ§Ã£o de aÃ§Ãµes anteriores).
    O teste garante cobertura para:
      - 'E' apÃ³s um passo 'Quando'
      - 'E' isolado (sem passo anterior de mesma categoria)
    """

    df = pd.DataFrame(
        [
            {
                "titulo": "CT com E apÃ³s Quando",
                "prioridade": "baixa",
                "cenario": [
                    "Dado que o usuÃ¡rio entra",
                    "Quando clica",
                    "E vÃª a tela inicial",
                ],
            },
            {
                "titulo": "CT com E isolado",
                "prioridade": "baixa",
                "cenario": ["Dado algo", "E outro passo"],
            },
        ]
    )

    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area/Teste", "QA")
    text = csv_bytes.decode("utf-8-sig")

    #  Ambos os passos com 'E' devem estar presentes
    assert "E vÃª a tela inicial" in text
    assert "E outro passo" in text
