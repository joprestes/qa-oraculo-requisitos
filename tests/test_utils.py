# ============================================================
# üìò test/test_utils.py ‚Äî Testes de unidade do m√≥dulo utils
# ============================================================
# Este arquivo cont√©m testes de unidade que validam o comportamento
# das fun√ß√µes utilit√°rias do projeto QA Or√°culo.
#
# Nesta se√ß√£o, testamos as fun√ß√µes fundamentais relacionadas a:
#   - Normaliza√ß√£o de strings
#   - Busca flex√≠vel de chaves em dicion√°rios
#   - Prepara√ß√£o de dados para exporta√ß√£o (Zephyr e Excel)
#   - Gera√ß√£o de nomes de arquivos seguros
#
# Cada teste aqui garante que as fun√ß√µes utilit√°rias mantenham
# a consist√™ncia e robustez da aplica√ß√£o em opera√ß√µes b√°sicas.
# ============================================================

import datetime
import io
import locale
import unittest
from io import BytesIO
from unittest.mock import patch

import pandas as pd
import pytest

import utils
from app import _ensure_bytes
from utils import (
    clean_markdown_report,
    gerar_nome_arquivo_seguro,
    gerar_relatorio_md_dos_cenarios,
    get_flexible,
    normalizar_string,
    parse_json_strict,
    preparar_df_para_zephyr_xlsx,
    to_excel,
)

# üî¢ Limite m√°ximo do nome base de arquivos gerados
MAX_FILENAME_BASE = 50

# ============================================================
# üîß Testes gerais de fun√ß√µes utilit√°rias
# ============================================================
# Esta classe agrupa os testes principais das fun√ß√µes utilit√°rias.
# Ela cobre os comportamentos de transforma√ß√£o de dados,
# manipula√ß√£o de texto e exporta√ß√£o de planilhas.
# ============================================================


class TestUtilsFunctions(unittest.TestCase):
    """üß© Classe que testa as principais fun√ß√µes do m√≥dulo utils."""

    def setUp(self):
        """
        üí° Executa antes de cada teste.
        Cria um DataFrame de exemplo que simula dois casos de teste:
        - Um cen√°rio ‚Äúfeliz‚Äù (fluxo principal)
        - Um cen√°rio ‚Äúinfeliz‚Äù (erro ou exce√ß√£o esperada)
        """
        self.sample_df = pd.DataFrame(
            [
                {
                    "titulo": "Caminho Feliz",
                    "prioridade": "alta",
                    "cenario": "Passo 1\nPasso 2",
                },
                {
                    "titulo": "Caminho Infeliz",
                    "prioridade": "m√©dia",
                    "cenario": "Passo A",
                },
            ]
        )

    def test_normalizar_string(self):
        """
        üí° Verifica se caracteres acentuados e cedilhas s√£o convertidos
        para suas vers√µes sem acentua√ß√£o.
        Exemplo: 'usu√°rio' ‚Üí 'usuario', '√ß' ‚Üí 'c'
        """
        self.assertEqual(
            normalizar_string("usu√°rio e relat√≥rio com √ß e √£"),
            "usuario e relatorio com c e a",
        )

    def test_get_flexible(self):
        """
        üí° Garante que a fun√ß√£o `get_flexible` consegue encontrar
        chaves alternativas em dicion√°rios com diferentes nomes de campos.
        Inclui valida√ß√£o de fallback e tipos inv√°lidos.
        """
        data = {"avaliacao_geral": "Bom", "riscos": ["Risco 1"]}

        # üß† Caso 1 ‚Äî Encontra a chave prim√°ria
        self.assertEqual(
            get_flexible(data, ["avaliacao_geral", "avaliacao"], "Padr√£o"), "Bom"
        )

        # üîÑ Caso 2 ‚Äî Encontra a chave alternativa
        self.assertEqual(
            get_flexible(data, ["riscos_e_dependencias", "riscos"], []), ["Risco 1"]
        )

        # üö´ Caso 3 ‚Äî Nenhuma chave encontrada (retorna valor padr√£o)
        self.assertEqual(
            get_flexible(data, ["pontos_ambiguos", "ambiguidades"], []), []
        )

        # ‚öôÔ∏è Caso 4 ‚Äî Entrada inv√°lida (n√£o √© dict)
        self.assertEqual(get_flexible(None, ["chave"], "Padr√£o"), "Padr√£o")
        self.assertEqual(get_flexible([], ["chave"], "Padr√£o"), "Padr√£o")

    def test_preparar_df_para_zephyr_xlsx(self):
        """
        üí° Testa se a fun√ß√£o converte corretamente um DataFrame de cen√°rios
        para o formato esperado pelo Jira Zephyr (planilha de importa√ß√£o).
        Espera-se que o n√∫mero de linhas exportadas seja igual ao n√∫mero
        de casos de teste + cabe√ßalho.
        """
        df_zephyr = preparar_df_para_zephyr_xlsx(self.sample_df, "High", "s1", "Desc")
        self.assertEqual(len(df_zephyr), 3)

    @patch("utils.datetime")
    def test_gerar_nome_arquivo_seguro(self, mock_datetime):
        """
        üí° Garante que o nome de arquivo gerado:
           - Remove caracteres especiais
           - Inclui timestamp de data/hora
           - Usa o padr√£o `relatorio_qa_oraculo` quando o nome estiver vazio
        """
        # üïí Define uma data fixa para prever o resultado
        mock_now = datetime.datetime(2024, 1, 1, 12, 0, 0)
        mock_datetime.datetime.now.return_value = mock_now

        # ‚úÖ Testa gera√ß√£o com nome customizado
        self.assertEqual(
            gerar_nome_arquivo_seguro("usu√°rio", "txt"), "usuario_20240101_120000.txt"
        )

        # ‚úÖ Testa fallback padr√£o (sem nome)
        self.assertEqual(gerar_nome_arquivo_seguro("", "md"), "relatorio_qa_oraculo.md")

    def test_to_excel_conversion(self):
        """
        üí° Garante a integridade da fun√ß√£o `to_excel`, verificando se:
           1Ô∏è‚É£ O DataFrame √© convertido para bytes.
           2Ô∏è‚É£ O arquivo pode ser reaberto e cont√©m os mesmos dados originais.
        """
        source_df = pd.DataFrame({"ID": [1, 2], "Nome": ["Teste A", "Teste B"]})
        sheet_name = "MinhaPlanilha"

        # üßæ Converte DataFrame ‚Üí Excel (em bytes)
        excel_bytes = to_excel(source_df, sheet_name)

        # ‚úÖ Deve retornar bytes v√°lidos
        self.assertIsInstance(excel_bytes, bytes)
        self.assertTrue(len(excel_bytes) > 0)

        # üîÅ Converte de volta para DataFrame e compara os dados
        result_df = pd.read_excel(io.BytesIO(excel_bytes), sheet_name=sheet_name)
        pd.testing.assert_frame_equal(source_df, result_df)


# ============================================================
# üß™ Testes extras (Markdown, JSON, ensure_bytes)
# ============================================================
# ============================================================
# üß™ Testes extras ‚Äî Markdown, JSON e _ensure_bytes
# ============================================================
# Esta se√ß√£o valida fun√ß√µes auxiliares do m√≥dulo utils,
# respons√°veis por:
#   - Limpar relat√≥rios em Markdown removendo cercas de c√≥digo
#   - Fazer parsing seguro de JSON retornado por IA (com e sem cercas)
#   - Converter objetos em bytes de forma resiliente
#
# Esses testes s√£o importantes pois garantem robustez na
# manipula√ß√£o de texto, exporta√ß√£o e comunica√ß√£o entre m√≥dulos.
# ============================================================


class TestUtilsExtras(unittest.TestCase):
    """üß© Testa fun√ß√µes auxiliares de limpeza e parsing do m√≥dulo utils."""

    def test_clean_markdown_report_completo(self):
        """
        üí° Garante que o texto entre cercas ```markdown e ``` seja extra√≠do corretamente.
        O conte√∫do fora dessas marca√ß√µes deve ser removido.
        """
        texto = "```markdown\n# T√≠tulo\n```"
        esperado = "# T√≠tulo"
        self.assertEqual(clean_markdown_report(texto), esperado)

    def test_clean_markdown_report_sem_cercas(self):
        """
        üí° Verifica o comportamento quando o texto n√£o cont√©m cercas de markdown.
        Nesse caso, o conte√∫do deve ser retornado inalterado.
        """
        texto = "# Apenas texto normal"
        self.assertEqual(clean_markdown_report(texto), "# Apenas texto normal")

    def test_clean_markdown_report_nao_string(self):
        """
        üí° Se o valor passado n√£o for uma string (ex: None),
        a fun√ß√£o deve retornar uma string vazia, evitando exce√ß√µes.
        """
        self.assertEqual(clean_markdown_report(None), "")

    def test_parse_json_strict_valido(self):
        """
        üí° Testa o parsing de um JSON puro, sem formata√ß√£o adicional.
        O resultado deve ser um dicion√°rio Python equivalente.
        """
        texto = '{"key": "value"}'
        self.assertEqual(parse_json_strict(texto), {"key": "value"})

    def test_parse_json_strict_com_cercas(self):
        """
        üí° Valida o comportamento com JSONs delimitados por ```json ... ```.
        A fun√ß√£o deve ignorar as cercas e decodificar o conte√∫do corretamente.
        """
        texto = '```json\n{"key": "value"}\n```'
        self.assertEqual(parse_json_strict(texto), {"key": "value"})

    def test_parse_json_strict_invalido(self):
        """
        üí° Quando o texto n√£o √© JSON v√°lido, a fun√ß√£o deve lan√ßar ValueError,
        mantendo a robustez contra entradas inesperadas.
        """
        with self.assertRaises(ValueError):
            parse_json_strict("n√£o √© json")


def test_gerar_relatorio_md_dos_cenarios_completo():
    """
    üí° Valida a fun√ß√£o `gerar_relatorio_md_dos_cenarios`, garantindo que:
       - Gere texto Markdown com blocos Gherkin
       - Inclua os campos principais de cada caso de teste
       - Trate corretamente DataFrames vazios
    """
    df = pd.DataFrame(
        [
            {
                "titulo": "Login v√°lido",
                "prioridade": "Alta",
                "criterio_de_aceitacao_relacionado": "Usu√°rio faz login com sucesso",
                "cenario": "Cen√°rio: Login v√°lido\nDado que o usu√°rio acessa\nQuando insere credenciais\nEnt√£o o login √© bem-sucedido",
            },
            {
                "titulo": "Login inv√°lido",
                "prioridade": "Baixa",
                "criterio_de_aceitacao_relacionado": "Usu√°rio insere senha incorreta",
                "cenario": "Cen√°rio: Login inv√°lido\nDado que o usu√°rio acessa\nQuando insere senha errada\nEnt√£o deve ver mensagem de erro",
            },
        ]
    )

    md = gerar_relatorio_md_dos_cenarios(df)

    # Deve conter se√ß√µes Markdown formatadas corretamente
    assert "### üß© Login v√°lido" in md
    assert "### üß© Login inv√°lido" in md
    assert "```gherkin" in md
    assert "Dado que o usu√°rio acessa" in md

    # Mesmo DF vazio deve retornar texto padr√£o, n√£o erro
    vazio = pd.DataFrame()
    vazio_md = gerar_relatorio_md_dos_cenarios(vazio)
    assert "Nenhum cen√°rio dispon√≠vel" in vazio_md


# ============================================================
# üß† Testes complementares independentes
# ============================================================
# Estes testes n√£o fazem parte da classe acima, mas cobrem
# varia√ß√µes e exce√ß√µes adicionais, garantindo cobertura total
# do m√≥dulo e de comportamentos extremos.
# ============================================================


def test_parse_json_strict_com_cercas_incompletas():
    """
    üí° Cobre o caso em que h√° apenas a abertura das cercas ```json,
    mas sem o fechamento final. A fun√ß√£o deve conseguir parsear o conte√∫do.
    """
    texto = '```json\n{"key": "value"}'
    assert utils.parse_json_strict(texto) == {"key": "value"}


def test_parse_json_strict_invalido_levanta():
    """
    üí° Caso o conte√∫do seja ileg√≠vel como JSON, o m√©todo
    deve lan√ßar uma exce√ß√£o ValueError, indicando falha no parsing.
    """
    with pytest.raises(ValueError):
        utils.parse_json_strict("n√£o √© json v√°lido")


def test_gerar_nome_arquivo_seguro_caracteres_invalidos():
    """
    üí° Garante que caracteres inv√°lidos em nomes de arquivo
    (como /, :, *, ?) sejam removidos e que a extens√£o final seja mantida.
    """
    nome = gerar_nome_arquivo_seguro("Hist√≥ria/Inv√°lida:*?", "txt")
    assert nome.endswith(".txt")
    assert "/" not in nome and ":" not in nome


def test_to_excel_dataframe_vazio():
    """
    üí° Mesmo um DataFrame vazio deve gerar um arquivo Excel v√°lido.
    A fun√ß√£o deve retornar um buffer de bytes, n√£o lan√ßar exce√ß√£o.
    """
    df = pd.DataFrame()
    buf = to_excel(df, sheet_name="Vazio")
    assert isinstance(buf, (bytes | bytearray))


def test_ensure_bytes_com_getvalue():
    """
    üí° Testa a fun√ß√£o `_ensure_bytes` com objetos que possuem
    o m√©todo `getvalue()`, como `BytesIO`.
    O retorno deve ser exatamente o conte√∫do em bytes.
    """
    obj = BytesIO(b"dados em bytes")
    assert _ensure_bytes(obj) == b"dados em bytes"


def test_ensure_bytes_com_bytes_diretos():
    """
    üí° Verifica o comportamento de `_ensure_bytes` quando recebe
    diretamente valores j√° em bytes ou bytearray.
    A fun√ß√£o deve apenas retorn√°-los sem modifica√ß√µes.
    """
    assert _ensure_bytes(b"ja sou bytes") == b"ja sou bytes"
    assert _ensure_bytes(bytearray(b"sou bytearray")) == b"sou bytearray"


# ============================================================
# üß™ NOVOS TESTES ‚Äî gerar_csv_azure_from_df
# ============================================================

EXPECTED_COLUMNS_COUNT = 10
EXPECTED_TEST_CASES_COUNT = 2


def test_gerar_csv_azure_from_df_basico(monkeypatch):
    """Valida estrutura, separador e ID vazio (locale PT-BR)."""
    df = pd.DataFrame(
        [
            {
                "titulo": "Login V√°lido",
                "prioridade": "Alta",
                "cenario": "Dado que o usu√°rio acessa\nQuando insere credenciais\nEnt√£o o login √© bem-sucedido",
            }
        ]
    )

    monkeypatch.setattr(locale, "getlocale", lambda: ("pt_BR", "UTF-8"))
    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area/Teste", "QA Tester")
    csv_text = csv_bytes.decode("utf-8-sig")
    linhas = [linha for linha in csv_text.splitlines() if linha.strip()]

    # Cabe√ßalho correto
    assert linhas[0].startswith("ID;Work Item Type;Title;Test Step;")
    # Cada linha tem 10 colunas
    for linha in linhas[1:]:
        campos = linha.split(";")
        assert len(campos) == EXPECTED_COLUMNS_COUNT
    # ID vazio
    assert linhas[1].split(";")[0] == ""


def test_gerar_csv_azure_from_df_locale_en(monkeypatch):
    """Garante que o separador mude para v√≠rgula em EN-US."""
    df = pd.DataFrame(
        [
            {
                "titulo": "Cadastro Usu√°rio",
                "prioridade": "Low",
                "cenario": "Dado que o usu√°rio abre o app\nEnt√£o v√™ a tela inicial",
            },
        ]
    )

    monkeypatch.setattr(locale, "getlocale", lambda: ("en_US", "UTF-8"))
    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area/EN", "QA EN")
    csv_text = csv_bytes.decode("utf-8-sig")
    header = csv_text.splitlines()[0]

    assert "," in header
    assert ";" not in header


def test_gerar_csv_azure_from_df_vazio():
    """Garante que DataFrame vazio gera apenas cabe√ßalho."""
    df_vazio = pd.DataFrame()
    csv_bytes = utils.gerar_csv_azure_from_df(df_vazio, "", "")
    csv_text = csv_bytes.decode("utf-8-sig").strip()
    linhas = csv_text.splitlines()

    assert len(linhas) == 1
    assert "Work Item Type" in linhas[0]
    assert linhas[0].startswith("ID")


def test_gerar_csv_azure_from_df_multiplos_casos(monkeypatch):
    """Cada linha do DF deve gerar um Test Case separado."""
    df = pd.DataFrame(
        [
            {
                "titulo": "CT 1",
                "prioridade": "Alta",
                "cenario": "Dado passo 1\nEnt√£o ok",
            },
            {
                "titulo": "CT 2",
                "prioridade": "Baixa",
                "cenario": "Dado passo 2\nEnt√£o outro ok",
            },
        ]
    )

    monkeypatch.setattr(locale, "getlocale", lambda: ("pt_BR", "UTF-8"))
    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area", "QA")
    csv_text = csv_bytes.decode("utf-8-sig")
    linhas = [linha for linha in csv_text.splitlines() if "Test Case" in linha]

    assert len(linhas) == EXPECTED_TEST_CASES_COUNT


def test_normalizar_string_vazia_ou_none():
    assert utils.normalizar_string("") == ""
    assert utils.normalizar_string("√°√©√≠√≥√∫") == "aeiou"
    # None deve levantar AttributeError (pois n√£o √© string)
    with pytest.raises(TypeError):
        utils.normalizar_string(None)


def test_gerar_nome_arquivo_seguro_truncamento():
    us = "Hist√≥ria muito longa " * 10  # cria um nome >50 chars
    nome = utils.gerar_nome_arquivo_seguro(us, "csv")
    assert nome.endswith(".csv")
    # o nome base deve ter no m√°ximo 50 caracteres antes do timestamp
    assert len(nome.split("_")[0]) <= MAX_FILENAME_BASE


def test_parse_json_strict_lixo_ao_redor():
    """
    Garante que parse_json_strict lan√ßa ValueError quando
    o texto cont√©m lixo antes ou depois das cercas de c√≥digo.
    Isso cobre o ramo de exce√ß√£o (json.JSONDecodeError).
    """
    texto = 'in√≠cio```json\n{"ok": true}\n```fim'
    with pytest.raises(ValueError):
        utils.parse_json_strict(texto)


def test_clean_markdown_report_cercas_incompletas():
    texto = "```markdown\n# T√≠tulo sem fechamento"
    result = utils.clean_markdown_report(texto)
    assert "# T√≠tulo" in result


def test_gerar_csv_azure_df_vazio_e_prioridade_invalida():
    df_vazio = pd.DataFrame()
    csv_bytes = utils.gerar_csv_azure_from_df(df_vazio, "Area", "Dev")
    assert b"Work Item Type" in csv_bytes  # s√≥ header

    df_invalida = pd.DataFrame(
        [{"titulo": "CT", "cenario": "Dado algo", "prioridade": "urgente"}]
    )
    csv_bytes2 = utils.gerar_csv_azure_from_df(df_invalida, "Area", "Dev")
    text = csv_bytes2.decode("utf-8-sig")
    # deve cair no default_priority ("2")
    assert ";2;" in text or ",2," in text


# ============================================================
# üß© Testes complementares ‚Äî Cobertura total (100%)
# ============================================================
# Esta se√ß√£o garante a cobertura completa do m√≥dulo utils.
# S√£o inclu√≠dos testes de exce√ß√µes, fluxos alternativos e
# comportamentos de borda. O objetivo √© validar que todas
# as ramifica√ß√µes l√≥gicas das fun√ß√µes sejam exercitadas.
# ============================================================


def test_ensure_bytes_tipo_invalido():
    """
    üí° For√ßa `_ensure_bytes` a lidar com tipos inesperados (int, dict).
    A fun√ß√£o deve converter qualquer tipo n√£o suportado em bytes
    chamando `str()` internamente.
    """
    assert _ensure_bytes(123) == b"123"
    # Para dicion√°rios, o retorno deve conter o caractere ‚Äú{‚Äù
    assert b"{" in _ensure_bytes({"a": 1})


def test_clean_markdown_report_com_fechamento_de_cercas():
    """
    üí° Verifica se a fun√ß√£o `clean_markdown_report` remove corretamente
    o fechamento de cercas de c√≥digo (```), mantendo apenas o conte√∫do.
    """
    texto = "# T√≠tulo\n```"
    result = utils.clean_markdown_report(texto)
    assert "```" not in result


def test_parse_json_strict_apenas_inicio_com_cercas():
    """
    üí° Garante a cobertura do caso em que o JSON cont√©m apenas
    a abertura das cercas (` ```json `) mas sem o fechamento final.
    O conte√∫do interno ainda deve ser interpretado corretamente.
    """
    texto = '```json\n{"a": 1}'
    result = utils.parse_json_strict(texto)
    assert result == {"a": 1}


def test_parse_json_strict_apenas_fim_com_cercas():
    """
    üí° Garante a cobertura do caso inverso: o JSON termina com as cercas
    de fechamento ``` mas n√£o tem abertura. A fun√ß√£o deve conseguir
    decodificar normalmente o conte√∫do.
    """
    texto = '{"b": 2}\n```'
    result = utils.parse_json_strict(texto)
    assert result == {"b": 2}


def test_gerar_csv_azure_locale_invalido(monkeypatch):
    """
    üí° For√ßa uma exce√ß√£o na detec√ß√£o do locale para garantir que
    a fun√ß√£o `gerar_csv_azure_from_df` utilize o fallback padr√£o.
    Mesmo sem locale v√°lido, o CSV deve ser gerado corretamente.
    """
    df = pd.DataFrame([{"titulo": "CT", "cenario": "Quando fa√ßo algo"}])

    # Simula falha no locale.getlocale()
    monkeypatch.setattr("locale.getlocale", lambda: (None, None))

    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area", "QA")

    # ‚úÖ Ainda deve retornar um arquivo v√°lido
    assert isinstance(csv_bytes, (bytes | bytearray))
    assert b"Test Case" in csv_bytes


def test_to_excel_erro_salvar(monkeypatch):
    """
    üí° For√ßa um erro interno no salvamento do Excel para cobrir o bloco `except`.
    Garante que o erro seja propagado corretamente como ValueError.
    """

    df = pd.DataFrame({"A": [1]})

    # Classe fict√≠cia que simula uma falha ao salvar o arquivo
    class DummyWriter:
        def __enter__(self):
            return self

        def __exit__(self, *a):
            pass

        def save(self):
            raise ValueError("Erro simulado")

    # Substitui o ExcelWriter do pandas pela classe DummyWriter
    monkeypatch.setattr("pandas.ExcelWriter", lambda *a, **k: DummyWriter())

    with pytest.raises(ValueError):
        utils.to_excel(df, "Sheet1")


def test_clean_markdown_report_final_com_cercas():
    """
    üí° Cobre o uso do `re.sub` interno que remove as cercas finais.
    O conte√∫do deve permanecer limpo e sem marcas de ``` no final.
    """
    texto = "# T√≠tulo\n```"
    result = utils.clean_markdown_report(texto)
    assert "```" not in result
    assert "# T√≠tulo" in result


def test_gerar_csv_azure_quando_sem_entao():
    """
    üí° Cobre o cen√°rio em que existe um passo 'Quando' mas n√£o h√°
    passo 'Ent√£o'. O CSV ainda deve ser gerado e conter o passo √∫nico.
    """
    df = pd.DataFrame(
        [{"titulo": "CT incompleto", "cenario": ["Quando clico no bot√£o"]}]
    )

    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area", "QA")
    text = csv_bytes.decode("utf-8-sig")

    # ‚úÖ Deve conter o passo 'Quando' no conte√∫do final
    assert "Quando clico no bot√£o" in text


def test_preparar_df_para_zephyr_cenario_vazio_cobre_continue():
    """
    üí° Cobre o ramo da linha 96 em `preparar_df_para_zephyr_xlsx`:
    `if not cenario_steps: continue`
    Garante que cen√°rios vazios (string vazia ou None) sejam ignorados
    sem gerar erro ou linha indevida no resultado.
    """
    df = pd.DataFrame(
        [
            {"titulo": "CT sem passos", "cenario": ""},
            {"titulo": "CT None", "cenario": None},
        ]
    )

    result = utils.preparar_df_para_zephyr_xlsx(df, "High", "QA", "Desc")

    # ‚úÖ Nenhum cen√°rio v√°lido ‚Üí resultado vazio
    assert result.empty


def test_gerar_csv_azure_cenario_tipo_invalido_cobre_linha_227():
    """
    üí° Cobre o trecho da linha 227 de `gerar_csv_azure_from_df`:
    `if not isinstance(cenario_steps, list)`
    Garante que valores de cen√°rio n√£o-lista (como inteiros) sejam
    tratados de forma segura, sem lan√ßar erro.
    """
    df = pd.DataFrame(
        [{"titulo": "CT tipo inv√°lido", "prioridade": "baixa", "cenario": 123}]
    )

    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area/Teste", "QA")
    text = csv_bytes.decode("utf-8-sig")

    # ‚úÖ O t√≠tulo deve existir, mas sem passos (cen√°rio ignorado)
    assert "CT tipo inv√°lido" in text
    assert "Dado" not in text and "Quando" not in text


def test_gerar_csv_azure_com_passos_com_e_cobre_279_288():
    """
    üí° Cobre o bloco das linhas 279-288 em `gerar_csv_azure_from_df`,
    que trata passos come√ßando com 'E ' (continua√ß√£o de a√ß√µes anteriores).
    O teste garante cobertura para:
      - 'E' ap√≥s um passo 'Quando'
      - 'E' isolado (sem passo anterior de mesma categoria)
    """

    df = pd.DataFrame(
        [
            {
                "titulo": "CT com E ap√≥s Quando",
                "prioridade": "baixa",
                "cenario": [
                    "Dado que o usu√°rio entra",
                    "Quando clica",
                    "E v√™ a tela inicial",
                ],
            },
            {
                "titulo": "CT com E isolado",
                "prioridade": "baixa",
                "cenario": ["Dado algo", "E outro passo"],
            },
        ]
    )

    csv_bytes = utils.gerar_csv_azure_from_df(df, "Area/Teste", "QA")
    text = csv_bytes.decode("utf-8-sig")

    # ‚úÖ Ambos os passos com 'E' devem estar presentes
    assert "E v√™ a tela inicial" in text
    assert "E outro passo" in text
